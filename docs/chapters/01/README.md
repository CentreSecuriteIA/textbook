# Chapter 1 - Capabilities

<div class="chapter-meta">

            <div class="meta-grid">
                <div class="meta-col">
                    
            <div class="meta-item">
                <span class="meta-icon">
                    <i class="fas fa-users"></i>
                </span>
                <div class="meta-content">
                    <div class="meta-label">Authors</div>
                    <div class="meta-value meta-list">
                        <div>Markov Grey, Charbel-Raphael Segerie</div>
                    </div>
                </div>
            </div>
             
            <div class="meta-item">
                <span class="meta-icon">
                    <i class="fas fa-building"></i>
                </span>
                <div class="meta-content">
                    <div class="meta-label">Affiliations</div>
                    <div class="meta-value meta-list">
                        <div>French Center for AI Safety (CeSIA)</div>
                    </div>
                </div>
            </div>
             
            <div class="meta-item">
                <span class="meta-icon">
                    <i class="fas fa-heart"></i>
                </span>
                <div class="meta-content">
                    <div class="meta-label">Acknowledgements</div>
                    <div class="meta-value meta-list">
                        <div>Jeanne Salle, Charles Martinet, Vincent Corruble</div>
                    </div>
                </div>
            </div>
            
                </div>
                <div class="meta-col">
                    
            <div class="meta-item">
                <span class="meta-icon">
                    <i class="fas fa-calendar"></i>
                </span>
                <div class="meta-content">
                    <div class="meta-label">Last Updated</div>
                    <div class="meta-value">2024-11-20</div>
                </div>
            </div>
             
            <div class="meta-item">
                <span class="meta-icon">
                    <i class="fas fa-link"></i>
                </span>
                <div class="meta-content">
                    <div class="meta-label">Also available on</div>
                    <div class="meta-value meta-links"><a href="https://ai-safety-atlas.com/chapters/01/" class="meta-link">AI Safety Atlas</a> · <a href="https://www.alignmentforum.org/posts/MkfaQyxB9PN4h8Bs9/" class="meta-link">Alignment Forum</a> · <a href="https://docs.google.com/document/d/1HKo0Kest9Xppjn7m2ODpfMUlEu93SzLsfxXBH48Xaus/edit?usp=sharing" class="meta-link">Google Docs</a></div>
                </div>
            </div>
            
                </div>
            </div>
            
</div>

[:fontawesome-solid-message: Feedback](https://forms.gle/ZsA4hEWUx1ZrtQLL9){ .md-button }
[:fontawesome-solid-video: Watch](https://www.youtube.com/watch?v=J_iMeH1hb9M){ .md-button }
[:fontawesome-solid-users: Facilitate](https://docs.google.com/document/d/1L32xCVUCWEsm-x8UZ3GSTgKnmBcC7rJQLLIh9wGLj40/edit?usp=sharing){ .md-button }

# Introduction

The field of artificial intelligence has undergone a remarkable transformation in recent years, with capabilities expanding at an unprecedented pace. This chapter provides a comprehensive examination of current AI capabilities, the fundamental principles driving their advancement, and frameworks for understanding and forecasting future progress.

Understanding artificial intelligence capabilities is fundamental to addressing AI safety challenges. This chapter lays the groundwork for the entire book by establishing what AI systems can currently do, how they achieve these capabilities, and how we might anticipate their future development. This foundation is essential for all subsequent chapters: our analysis of potential risks (Chapter 2) stems directly from understanding capabilities; proposed technical (Chapter 3) and governance solutions (Chapter 4) both must account for the current and projected future of AI capabilities.

<figure markdown="span">
![Enter image alt description](Images/7B0_Image_1.png){ loading=lazy }
  <figcaption markdown="1"><b>Figure:</b> This is the flow that the chapter will be following</figcaption>
</figure>

**State-of-the-Art AI - Achieved breakthrough capabilities across multiple domains**. We begin by exploring how AI systems have evolved from narrow, specialized tools to increasingly general-purpose technologies. Language models can now engage in complex reasoning, while computer vision systems demonstrate sophisticated understanding of visual information. In robotics, we're seeing the emergence of systems that can learn and adapt to real-world environments with increasing autonomy. These advances across different domains paint a picture of rapidly expanding AI capabilities.

**Foundation models - Revolutionized how we build AI systems. **The next section explores how we have moved from smaller specialized architectures to large scale general-purpose architectures. Rather than building separate systems for each task, these foundation models serve as the starting point. They are building blocks that can be later adapted for various applications using fine-tuning. We explore how these models are trained, their key properties, and the unique challenges they present. The emergence of unexpected capabilities from these models raises important questions about both their potential and implications for AI Safety.

**Understanding Intelligence - Capabilities require precise measurement to guide safety work**. The objective of this section is to provide an understanding of what terms like artificial general intelligence and artificial superintelligence actually mean in practice. Through detailed case studies and empirical observations, we examine different approaches to defining and measuring AI capabilities. Moving beyond traditional binary distinctions between "narrow" and "general" AI, we introduce more nuanced formal frameworks that track progress along multiple dimensions, essential for understanding when and how safety measures need to be implemented.

**Scaling - The bitter lesson and empirical scaling laws show that scale drives progress**. We explore how simple algorithms plus massive computation often outperform sophisticated hand-crafted approaches. This leads us to examine scaling laws that describe how AI performance improves with different variables like - data, parameter count and increased computational resources. This section also contains an examination of the debate around whether scale alone is sufficient for achieving transformative AI capabilities.

**Forecasting - Predicting capabilities progress helps us prepare safety measures in advance**. Building on our understanding of current capabilities and scaling behaviors, we examine various approaches to anticipating future progress. From biological anchors to trend analysis, we explore frameworks for making informed predictions about AI development trajectories, crucial for knowing when different safety measures need to be in place.

**Appendices - Overview of expert opinions on AI, detailed debates around scale, and scaling trends.** We consider these sections optional, but still useful to those who want to get a little bit of a deeper dive. The chapter concludes with appendices examining expert opinions on AI progress, deeper discussions about the nature and limitations of large language models, and comprehensive data on key trends in AI development.

Through this progression – from current capabilities to underlying principles, measurement frameworks, scaling dynamics, and forecasting methodologies – we develop a comprehensive picture of artificial intelligence's current state and potential future trajectory. This understanding is crucial for addressing the safety and governance challenges explored in subsequent chapters.
