
















<!--ACDC: Automatic Circuit DisCovery-->

<!--activations: The outputs produced by neurons or units in a neural network after processing input data through a layer.-->

<!--activation patching: A method used for understanding which components of a model are responsible for specific behaviors by replacing activations from one input with those from another and observing the impact on output.-->

<!--activation steering: A technique for controlling a model’s output by modifying its activations during inference, directing the model toward desired outcomes without retraining.-->

<!--channel: A channel refers to a dimension within a layer’s activations.-->

<!--channels: Channels refer to a dimension within a layer’s activations.-->

<!--circuit: Collection of neurons or components that work together to perform a specific function.-->

<!--circuits: Collections of neurons or components that work together to perform specific functions-->

<!--CNN: Convolutional Neural Network, a type of neural network primarily used for image classification, object detection, and pattern recognition.-->

<!--CNNs: Convolutional Neural Networks, a type of neural networks primarily used for image classification, object detection, and pattern recognition.-->

<!--deceptively aligned model: A model that pretends to be aligned during training but engages in dangerous behavior during deployment. During training it acts helpful, honest and harmless, but in deployment it acts according to a dangerous secret goal.-->

<!--feature: A specific pattern or characteristic that a neural network learns to detect, which may represent anything from low-level textures to high-level concepts.-->

<!--feature map: A feature map is the output of a layer in a convolutional neural network.-->

<!--feature maps: Feature maps are the output of a layer in a convolutional neural network.-->

<!--monosemantic neurons: neurons that respond to just one specific feature or stimulus.-->

<!--monosemantic neuron: neuron that responds to just one specific feature or stimulus.-->

<!--polysemantic neurons: neuron that activates in response to a variety of distinct features.-->

<!--polysemantic neurons: neurons that activate in response to a variety of distinct features.-->

<!--polysemanticity: The empirical phenomenon where a single neuron or model component responds to multiple, unrelated features.-->

<!--SAE: Sparse Autoencoder, a type of autoencoder designed to disentangle features that a model has learned.-->

<!--SAEs: Sparse Autoencoders, a type of autoencoders designed to disentangle features that a model has learned.-->

<!--Sparse Autoencoder: A type of autoencoder designed to disentangle features that a model has learned.-->

<!--superposition hypothesis: The superposition hypothesis posits that neural networks efficiently store more features than they have neurons by encoding features as overlapping linear combinations across multiple neurons.-->

<!--weights: The parameters of a neural network that determine the strength of the connection between neurons, learned during training to optimize the model’s performance.-->
