<!--File: textbook/docs/index.md-->

# The AI Safety Atlas

!!! warning "This textbook is still under construction. It will be updated regularly."

[Read the Book](chapters/index.md){ .md-button }

## **Overview**

<!--<h2 align="left">A comprehensive guide</h2>-->

<!-- ![AI Safety](https://lh7-us.googleusercontent.com/XuuImYOYY7YElHDnooD6S7k1tf11JAV_a7LQZ6IUXbItUbPp0p7sAgDp1EjHJAuuHvZ_cJ-pj7rGq7SLxb0O4Xe9OkyRIEKh4R8TwoUwERq8TJxKRMQdixUPBjXXwVEjog_AqBgNiCwvE9QHEHlr_rk) -->


Currently, AI Safety educational materials often rely heavily on a patchwork of many external links to blog posts and research papers. This content varies in terms of technical depth and communication style, posing a significant barrier to coherent learning. We are writing a textbook that aims to unify the disparate narratives in the field of AI Safety into a seamless end-to-end narrative. This helps improve the learning experience for newcomers, while at the same time also providing a single unified reference text for existing researchers in the field.

This textbook is designed to serve as the central comprehensive educational resource for the AI safety field bringing together, organizing and presenting arguments on AI Safety from research papers, blog posts, seminars and lectures, etc.

To get a glimpse of the amount of papers and research that will be distilled into this central resource check [Markov's Zotero for the project](https://www.zotero.org/groups/5540649/ai_safety_textbook/library).

We also plan to provide slide decks, online videos, and exercises alongsid the textbook which can be easily incorporated into university courses.

The alignment field is a pre-paradigmatic, and there is no right or wrong research direction, or a consensus for many of the concepts that this textbook will present. Please read the book critically and feel free to add feedback on this [form](https://docs.google.com/forms/d/e/1FAIpQLSe-UI2pt99SHaH2RFPVbDdmo8nuiRBZcxl49rBh67Guj6_p5Q/viewform) if something seems unclear, or needs to be improved.

<div class="grid cards" markdown>

- :material-book-multiple:{ .lg .middle } **Comprehensive**

    ---

    Covering all essential topics, this resource equips you with the knowledge needed to contribute effectively to the field of AI Safety.

    [:octicons-arrow-right-24: See the list of Chapters](chapters/index.md)

- :material-school:{ .lg .middle } **Pedagogical**

    ---

    AI Safety can be difficult to navigate, we've organized the information to be as accessible and easy to read as possible.

    [:octicons-arrow-right-24: Why a new textbook? Read our FAQ](https://manifund.org/projects/ai-safety-textbook#(e):~:text=Additional%20details/Potential%20questions)

- :material-account-group:{ .lg .middle } **Field-Tested**

    ---

    Proven effective in diverse educational settings, our content is already being utilized in various universities, bootcamps, and reading groups.

    [:octicons-arrow-right-24: Courses using this book](courses.md)

- :material-laptop:{ .lg .middle } **Interactive**

    ---

    Enhance your learning with questions, summaries, and Anki cards for a more interactive experience. (Coming soon)

- :material-update:{ .lg .middle } **Kept Up to Date**

    ---

    We want this resource to evolve with the field. We incorporate the latest research and developments.

- :material-headphones:{ .lg .middle } **Multi-Modal**

    ---

    Access an audio version of this course for learning on the go. (Coming soon)

</div>

!!! quote "Reception"
    *“*I found it to be very well written and super insightful. Learned tons of new things. Looking forwards to continue reading.*” - Participant of ML4G Germany 2023.
    * “*I liked the text, was well written, concise, easy to follow, contained many important points.*” - Participant of ML4G Germany 2023.
    *“*The textbooks are very helpful to keep a clear line of thought and a better structure.*”  - Participant of ML4G France 2023.
    * “*The material and content are great, thank you for writing it and I can't wait to read it in its entirety.*” - Participant of ML4G France 2023.

## **About**

!!! note "Contact Information"
    This textbook was created by Charbel-Raphael Segerie, Markov Grey, Jeanne Salle, and Vincent Corruble. We are actively looking for funding to be able to continue working on this project. Please consider either reaching out, or upvoting us on [Manifund](https://manifund.org/projects/ai-safety-textbook) if you like our work.

    Contacts: [Charbel-Raphael Segerie](mailto:crsegerie@gmail.com), [Markov Grey](mailto:ai_safety_textbook.y4wqu@slmail.me).
