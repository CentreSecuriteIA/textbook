---
title: Home
---
# The AI Safety Handbook

!!! warning "This textbook is still under construction. It will be updated regularly."

[Read the Book](Chapters/index.md){ .md-button }

## **Overview**

<!--<h2 align="left">A comprehensive guide</h2>-->

<!--![AI Safety](https://lh7-us.googleusercontent.com/XuuImYOYY7YElHDnooD6S7k1tf11JAV_a7LQZ6IUXbItUbPp0p7sAgDp1EjHJAuuHvZ_cJ-pj7rGq7SLxb0O4Xe9OkyRIEKh4R8TwoUwERq8TJxKRMQdixUPBjXXwVEjog_AqBgNiCwvE9QHEHlr_rk)-->

Currently, AI Safety courses rely heavily on a patchwork of many external links to blog posts and research papers (e.g. [AISF](https://course.aisafetyfundamentals.com/alignment?session=1)). This content varies in terms of technical depth and communication style, posing a significant barrier to coherent learning. We are writing a textbook that aims to unify these into a seamless narrative, to help improve the learning experience. We also want to include in our curriculum important considerations that are often neglected in other courses.

Our textbook is designed to serve as a comprehensive educational resource for the AI safety field. This will include an adaptation of the Turing Seminar, which is an accredited course with talks, workshops, and exercises at Ecole Normale Superieure (ENS) Ulm, and ENS Paris-Saclay in France. The original syllabus for the seminar was loosely inspired by the AI Safety Fundamentals (AISF) curriculum that I teach at [Master MVA](https://www.master-mva.com/cours/seminaire-turing/).

The alignment field is a pre-paradigmatic, and there is no consensus on many of the concepts presented. Please read the book critically and feel free to add feedback on this [form](https://docs.google.com/forms/d/e/1FAIpQLSe-UI2pt99SHaH2RFPVbDdmo8nuiRBZcxl49rBh67Guj6_p5Q/viewform) on the various chapters if something seems unclear.

!!! quote "Reception"
    * “*I found it to be very well written and super insightful. Learned tons of new things. Looking forwards to continue reading.*” - Participant of ML4G Germany 2023.
    * “*I liked the text, was well written, concise, easy to follow, contained many important points.*” - Participant of ML4G Germany 2023.
    * “*The textbooks are very helpful to keep a clear line of thought and a better structure.*”  - Participant of ML4G France 2023.
    * “*The material and content are great, thank you for writing it and I can't wait to read it in its entirety.*” - Participant of ML4G France 2023.


## **About**

!!! note "Contact Information"
    This textbook was created by Charbel-Raphael Segerie, Markov Grey, Jeanne Salle, and Vincent Corruble. We are actively looking for funding to be able to continue working on this project. Please consider either reaching out, or upvoting us on [Manifund](https://manifund.org/projects/ai-safety-textbook) if you like our work.

    Contacts: [Charbel-Raphael Segerie](mailto:crsegerie@gmail.com), [Markov Grey](mailto:ai_safety_textbook.y4wqu@slmail.me).

