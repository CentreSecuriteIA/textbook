<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Why do we need oversight? As AI systems get smarter, they will start doing tasks that are hard for humans to evaluate. Evaluation means checking how well the AI did after completing a task, while feedback is the information we give to the AI during or after it works to help it learn and improve. Right now, we can still use methods like Reinforcement Learning from Human Feedback (RLHF) to guide AI in the right direction. But we can only give feedback if we can still evaluate the outputs. As tasks get more complex, even experts might struggle to provide accurate evaluations and feedback. So, we need new ways to give accurate feedback, even for tasks that are beyond human expertise. This is the goal of scalable oversight."><link href=https://ai-safety-atlas.com/chapters/08/01/ rel=canonical><link href=../ rel=prev><link href=../02/ rel=next><link rel=icon href=../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.14"><title>8.1 - Oversight - AI Safety Atlas</title><link rel=stylesheet href=../../../assets/stylesheets/main.342714a4.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../overrides/css/base.css><link rel=stylesheet href=../../../overrides/css/buttons.css><link rel=stylesheet href=../../../overrides/css/tippy.css><link rel=stylesheet href=../../../overrides/css/tabs.css><link rel=stylesheet href=../../../overrides/css/typography.css><link rel=stylesheet href=../../../overrides/css/admonitions.css><link rel=stylesheet href=../../../overrides/css/navigation.css><link rel=stylesheet href=../../../overrides/css/metadata.css><link rel=stylesheet href=../../../overrides/css/figures.css><link rel=stylesheet href=../../../overrides/css/footer.css><link rel=stylesheet href=../../../overrides/css/section-end.css><link rel=stylesheet href=../../../overrides/css/scroll-buttons.css><link rel=stylesheet href=../../../overrides/css/home/base.css><link rel=stylesheet href=../../../overrides/css/home/hero.css><link rel=stylesheet href=../../../overrides/css/home/hero-animation.css><link rel=stylesheet href=../../../overrides/css/home/header.css><link rel=stylesheet href=../../../overrides/css/home/why.css><link rel=stylesheet href=../../../overrides/css/header.css><link rel=stylesheet href=../../../overrides/css/audio-player.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&display=swap"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Crimson+Pro:wght@700;800;900&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Cinzel:wght@600;700;800;900&display=swap"><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><link href=../../../assets/stylesheets/glightbox.min.css rel=stylesheet><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style><script src=../../../assets/javascripts/glightbox.min.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#81-oversight class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="AI Safety Atlas" class="md-header__button md-logo" aria-label="AI Safety Atlas" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> AI Safety Atlas </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 8.1 - Oversight </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Home </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> Book </a> </li> <li class=md-tabs__item> <a href=../../../feedback/ class=md-tabs__link> Feedback </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="AI Safety Atlas" class="md-nav__button md-logo" aria-label="AI Safety Atlas" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> AI Safety Atlas </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex> <span class=md-ellipsis> Book </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Book </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1 checked> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <span class=md-ellipsis> Chapters </span> </a> <label class="md-nav__link " for=__nav_2_1 id=__nav_2_1_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_1_label aria-expanded=true> <label class=md-nav__title for=__nav_2_1> <span class="md-nav__icon md-icon"></span> Chapters </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../01/ class=md-nav__link> <span class=md-ellipsis> 01 - Capabilities </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../02/ class=md-nav__link> <span class=md-ellipsis> 02 - Risks </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../03/ class=md-nav__link> <span class=md-ellipsis> 03 - Strategies </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../04/ class=md-nav__link> <span class=md-ellipsis> 04 - Governance </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../05/ class=md-nav__link> <span class=md-ellipsis> 05 - Evaluations </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../06/ class=md-nav__link> <span class=md-ellipsis> 06 - Specification </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../07/ class=md-nav__link> <span class=md-ellipsis> 07 - Generalization </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1_9 checked> <div class="md-nav__link md-nav__container"> <a href=../ class="md-nav__link "> <span class=md-ellipsis> 08 - Scalable Oversight </span> </a> <label class="md-nav__link " for=__nav_2_1_9 id=__nav_2_1_9_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_1_9_label aria-expanded=true> <label class=md-nav__title for=__nav_2_1_9> <span class="md-nav__icon md-icon"></span> 08 - Scalable Oversight </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> 8.1 - Oversight </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 8.1 - Oversight </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#01 class=md-nav__link> <span class=md-ellipsis> 8.1.1 Training Signals &amp; Fuzzy Tasks </span> </a> </li> <li class=md-nav__item> <a href=#02 class=md-nav__link> <span class=md-ellipsis> 8.1.2 Verification vs. Generation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../02/ class=md-nav__link> <span class=md-ellipsis> 8.2 - Task Decomposition </span> </a> </li> <li class=md-nav__item> <a href=../03/ class=md-nav__link> <span class=md-ellipsis> 8.3 - Process Oversight </span> </a> </li> <li class=md-nav__item> <a href=../04/ class=md-nav__link> <span class=md-ellipsis> 8.4 - Iterated Amplification </span> </a> </li> <li class=md-nav__item> <a href=../05/ class=md-nav__link> <span class=md-ellipsis> 8.5 - Debate </span> </a> </li> <li class=md-nav__item> <a href=../06/ class=md-nav__link> <span class=md-ellipsis> 8.6 - Weak-to-Strong (W2S) </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../09/ class=md-nav__link> <span class=md-ellipsis> 09 - Interpretability </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../feedback/ class=md-nav__link> <span class=md-ellipsis> Feedback </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#01 class=md-nav__link> <span class=md-ellipsis> 8.1.1 Training Signals &amp; Fuzzy Tasks </span> </a> </li> <li class=md-nav__item> <a href=#02 class=md-nav__link> <span class=md-ellipsis> 8.1.2 Verification vs. Generation </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=81-oversight>8.1 Oversight<a class=headerlink href=#81-oversight title="Permanent link">&para;</a></h1> <div class=section-meta> <div class=meta-item> <span class=meta-icon> <i class="fas fa-clock"></i> </span> <div class=meta-content> <div class=meta-label>Reading Time</div> <div class=meta-value>9 min</div> </div> </div> </div> <p><strong>Why do we need oversight?</strong> As AI systems get smarter, they will start doing tasks that are hard for humans to evaluate. Evaluation means checking how well the AI did after completing a task, while feedback is the information we give to the AI during or after it works to help it learn and improve. Right now, we can still use methods like Reinforcement Learning from Human Feedback (<abbr title="Reinforcement Learning from Human Feedback. A method for training AI using human feedback as training signals.">RLHF</abbr>) to guide AI in the right direction. But we can only give feedback if we can still evaluate the outputs. As tasks get more complex, even experts might struggle to provide accurate evaluations and feedback. So, we need new ways to give accurate feedback, even for tasks that are beyond human expertise. This is the goal of scalable oversight.</p> <p>Scalable Oversight techniques help humans provide accurate feedback on tasks to ensure AI systems are aligned with our goals, even after the task complexity outstrips the ability of the best human experts. This can happen during the AI's training or deployment and isn't limited to <abbr title="Reinforcement Learning from Human Feedback. A method for training AI using human feedback as training signals.">RLHF</abbr>-style feedback.</p> <figure> <a class=glightbox href=../Images/AUj_Image_1.png data-type=image data-width=100% data-height=auto data-desc-position=bottom><img alt="Enter image alt description" loading=lazy src=../Images/AUj_Image_1.png></a> <br> <figcaption><b>Figure 8.1:</b> The difference between regular oversight safety research, and scalable oversight safety research.</figcaption> </figure> <p><strong>Aligning RL Agents vs. LLMs</strong> . A few years ago it looked like the path to AGI was by training deep RL agents from scratch in a wide range of games and multi-agent environments. These agents would be aligned to maximizing simple score functions such as survival and winning games and wouldn’t know much about human values. Aligning the resulting agents would require a lot of effort: not only do we have to create a human-aligned objective function from scratch, we’d likely also need to instill new capabilities into the agents like understanding human society, what humans care about, and how humans think. Large language models (LLMs) make this a lot easier: they come preloaded with a lot of humanity’s knowledge, including detailed knowledge about human preferences and values. Out of the box they aren’t agents who are trying to pursue their own goals in the world, and their objective functions are quite malleable. For example, they are surprisingly easy to train to behave more nicely. If AGI comes out of LLMs it might be easier to align. (<a href=https://aligned.substack.com/p/alignment-optimism>Leike, 2022</a>)</p> <h2 id=01>8.1.1 Training Signals &amp; Fuzzy Tasks<a class=headerlink href=#01 title="Permanent link">&para;</a></h2> <p>Before we understand how to actually align smarter than human AIs, we need to understand the general concept of training signals and why they are getting increasingly harder to generate as AI is starting to display higher levels of general purpose capabilities.</p> <p><strong>What are training signals?</strong> Training signals is a general term that we use for inputs that are used to guide AI learning. They can be rewards, labels, or evaluations indicating how well the AI is performing a task. For example:</p> <ul> <li> <p>In supervised learning (SL), the training signal is the correct label for each example.</p> </li> <li> <p>For large language models (LLMs) using self-supervised learning (SSL), training signals are the correct next word in a sentence during pre-training. Human feedback on the quality of responses during fine-tuning is also a type of training signal guiding the outputs in a direction we want (a more “aligned” direction).</p> </li> <li> <p>In reinforcement learning (RL), training signals are rewards based on the success/failure of actions (or multiple actions), like points scored in a game or successful navigation to a location.</p> </li> </ul> <p>These signals shape how AI systems learn and are used to both evaluate performance and provide feedback.</p> <p><strong>Easy-to-generate training signals.</strong> For some tasks, generating training signals is simple. AlphaGo Zero, an RL agent playing Go, is a good example of this. The game has clear rules and win/loss outcomes, so training signals are straightforward: algorithmically generated win and lose signals directly measure performance, making it easy for the model to learn and improve its gameplay.</p> <p><strong>Hard-to-generate training signals.</strong> For other tasks, creating training signals is much harder. For example, training GPT models to generate accurate text summaries is challenging. The AI needs to convey correct information while being coherent and interesting. Success is subjective. Since it depends on individual reader preferences, it is hard to define clear, algorithmically generated training signals. Another example is self-driving cars navigating through busy city streets. These cars need to make real-time decisions, and the training signals or rewards for safe and efficient navigation are difficult to define due to varying contexts and sometimes conflicting traffic laws and safety considerations.</p> <p><strong>Fuzzy tasks.</strong> We call tasks where training signals are hard to generate “fuzzy tasks“. These tasks generally have ambiguous or ill-defined objectives and outcomes. We can’t generate precise training signals due to inherent subjectivity and variability in “correct responses”. Fuzzy tasks lack clear, objective criteria for success. Unlike well-defined tasks with specific, measurable goals, fuzzy tasks are more open-ended, which complicates our job of coming up with training signals. If it's difficult to provide precise rewards or labels that accurately capture the desired behavior, the training process becomes complicated. AI systems might not receive the consistent, reliable feedback needed to learn effectively. This is essentially highlighting again the difficulty of the reward specification problem that we talked about in previous chapters.</p> <p><strong>Fuzzy tasks and Scalable Oversight.</strong> Fuzzy tasks are closely related to AI alignment, where ensuring AI systems act in accordance with human values and intentions is challenging due to ambiguity and subjectivity. Aligning AI with human values is a fuzzy task. Oversight techniques aim to solve alignment by providing training signals for fuzzy tasks, including feedback and imitation learning techniques like <abbr title="Reinforcement Learning from Human Feedback. A method for training AI using human feedback as training signals.">RLHF</abbr>, <abbr title="Reinforcement Learning from Constitutional AI. A method for training AI using AI feedback based upon a constituion as training signals.">Constitutional AI</abbr> (<abbr title="Reinforcement Learning from Constitutional AI. A method for training AI using AI feedback based upon a constituion as training signals.">CAI</abbr>), and Inverse Reinforcement Learning (IRL). Scalable oversight techniques aim to provide training signals for fuzzy tasks that are too complex for even experts to understand or evaluate.</p> <p>To make scalable oversight techniques viable verification needs to be easier than generation, and preferably (but not necessarily) tasks should be decomposable. These properties will be discussed in the next sections.</p> <h2 id=02>8.1.2 Verification vs. Generation<a class=headerlink href=#02 title="Permanent link">&para;</a></h2> <p><strong>What Does P ≠ NP Mean?</strong> In computer science, we classify problems based on how hard they are to solve (generate a solution) and how hard they are to check (verify a solution).</p> <ul> <li> <p>P (Polynomial time): These are problems that a computer can solve quickly.</p> </li> <li> <p>NP (Nondeterministic Polynomial time): These are problems where, if you have a solution, you can check it quickly, but finding the solution might take a long time.</p> </li> </ul> <p><strong>What is generation?</strong> Generation is the process of coming up with solutions from scratch. This means searching through many possibilities, which can take a lot of time and computing power. For example, solving a Sudoku puzzle involves filling a 9x9 grid with numbers so that each row, column, and 3x3 subgrid contains all the digits from 1 to 9 without repeating. If you've ever tried to solve a Sudoku puzzle, you know it involves a lot of trial and error to make sure all the rules are followed.</p> <figure> <a class=glightbox href=../Images/BbW_Image_2.png data-type=image data-width=100% data-height=auto data-desc-position=bottom><img alt="Enter image alt description" loading=lazy src=../Images/BbW_Image_2.png></a> <br> <figcaption><b>Figure 8.2:</b> (<a href=https://en.wikipedia.org/wiki/Sudoku>Wikipedia</a>)</figcaption> </figure> <p>Generation here involves filling in the blank grid while ensuring all the constraints (unique numbers in rows, columns, and subgrids) are satisfied.</p> <p><strong>What is verification?</strong> Verification is the process of checking whether a given solution attempt is correct. Using the Sudoku example, verification means making sure that each row, column, and subgrid contains all the digits from 1 to 9 without any repeats. Once someone gives you a completed Sudoku puzzle, checking whether it's correct is straightforward and quick. This idea is central to the concept of P ≠ NP.</p> <figure> <a class=glightbox href=../Images/0Dt_Image_3.png data-type=image data-width=100% data-height=auto data-desc-position=bottom><img alt="Enter image alt description" loading=lazy src=../Images/0Dt_Image_3.png></a> <br> <figcaption><b>Figure 8.3:</b> (<a href=https://en.wikipedia.org/wiki/Sudoku>Wikipedia</a>)</figcaption> </figure> <p><strong>Examples: Illustrating Verification is Easier Than Generation</strong> . This is a very general property that holds across many domains:</p> <ul> <li> <p>Formal Problems: In computational complexity theory, most computer scientists believe that P ≠ NP (<a href="https://en.wikipedia.org/wiki/P_versus_NP_problem#Reasons_to_believe_P_%E2%89%A0_NP_or_P_=_NP">Wikipedia</a>), which means there are many problems where checking a solution is easier than finding one. This is seen in tasks like solving SAT problems or graph algorithms.</p> </li> <li> <p>Sports and Games: It's easier to look at a football scoreboard to see who is winning than it is to play the game well.</p> </li> <li> <p>Consumer Products: Comparing the quality of smartphones based on user reviews is simpler than designing and building a new smartphone.</p> </li> <li> <p>Job Performance: Evaluating how well an employee is doing is less demanding than actually doing the job.</p> </li> <li> <p>Academic Research: While reviewing research can be tough, it's still less work than producing new research.</p> </li> </ul> <p><strong>Why Verification Being Easier Than Generation Matters for Scalable Oversight</strong> . This fact is crucial for scalable oversight because it allows us as human overseers to efficiently ensure the correctness and safety of outputs produced by complex systems without needing to fully understand or replicate the entire generation process. If P ≠ NP is true , it implies that we might be able to trust and delegate alignment research itself to AI models, because we can comparatively easily verify that their solutions work while they have to do the hard task of generating the solutions to alignment. Overall operating under this assumption can make the task of aligning advanced AI systems seem more feasible. The next few paragraphs go into the debate of how valid this assumption is.</p> <p><strong>Verification in Adversarial Contexts</strong> . When verifying something in situations where someone might be actively trying to trick or attack you, the process becomes much harder. Put another way, if we have AIs that are deceptive, the problem becomes significantly trickier. For example, making sure software is secure against all possible attacks can be tougher than writing the software in the first place. An attacker only needs to find one security hole, but the person verifying must check everything to ensure there are no holes. This makes verification very challenging. Similarly creating a secure system in cryptography is hard, but proving that it’s secure against all possible attacks is even more difficult. You need to consider every potential way someone might try to break the system, which is a huge task.</p> <p><strong>Easier than generation does not mean verification is trivial</strong> . Just because verification is theoretically easier than generation doesn’t mean it’s always easy in practice. For example, checking a complex mathematical proof can be very hard. Writing the proof takes creativity and deep understanding, but verifying it requires careful and detailed checking, which can be exhausting and prone to mistakes. In the case of software, writing secure software is challenging, but verifying that it’s completely secure is even harder. Even though verifying a problem’s solution might be easier than generating the solution, the process can still be very difficult and require significant effort and expertise.</p> <p><strong>Verification of Safety vs. Provable Alignment</strong> . In the event that we have to deal with <abbr title="An AI with cognitive abilities far greater than those of humans in a wide range of important domains.">superintelligent</abbr> AI, just verifying its behavior might not be enough. Some researchers argue that we need to prove that the AI will always act in ways that align with human values. Verification means checking whether the AI behaves correctly in specific situations. Provable alignment means giving solid evidence that the AI will act correctly in every possible situation, even new and unexpected ones. This requires more than just checking—it needs formal methods and guarantees, which is extremely difficult.</p> <p><strong>Verification vs. Mathematical Proof</strong> . Verification involves checking if a specific solution is correct, usually through testing or inspection. A mathematical proof, on the other hand, is a rigorous logical argument that shows a statement is always true. For example, verifying a Sudoku solution checks if the given arrangement is correct, while a mathematical proof might show that any Sudoku puzzle with a certain number of clues always has a unique solution.</p> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=footer.title> <a href=../ class="md-footer__link md-footer__link--prev" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction>Previous</span> Chapter 08 </div> </div> </a> <a href=../02/ class="md-footer__link md-footer__link--next" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction>Next</span> 8.2 - Task Decomposition </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=footer-social-container> <hr class=footer-line> <div class=footer-social> <a href=https://github.com/CentreSecuriteIA class="footer-social__link github" title=GitHub> <i class="fab fa-github"></i> </a> <a href=https://youtube.com/@securite-ia class="footer-social__link youtube" title=YouTube> <i class="fab fa-youtube"></i> </a> <a href=https://discord.gg/YtatCZ3SQ8 class="footer-social__link discord" title=Discord> <i class="fab fa-discord"></i> </a> </div> <hr class=footer-line> </div> <div class=footer-identity> <a href=https://www.securite-ia.fr/ class=footer-logo target=_blank rel=noopener> <img src=https://ai-safety-atlas.com/assets/CeSIA_transparent_white_pure.png alt="CeSIA - French Center for AI Safety"> </a> </div> <div class=footer-info> <div class=footer-links> <a href=mailto:contact@securite-ia.fr>Contact</a> <span class=separator>•</span> <a href=https://forms.gle/Z3rzFfCrLJdDv8HDA>Feedback</a> </div> <div class=footer-legal> <span>© Copyright 2025 </span> <span class=separator>•</span> <span>Text Content: <a href=https://creativecommons.org/licenses/by-sa/4.0/ >CC BY-SA 4.0</a></span> <span class=separator>•</span> <span>Code: <a href=https://opensource.org/licenses/MIT>MIT</a></span> </div> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["navigation.tabs", "navigation.indexes", "navigation.footer", "navigation.sections", "navigation.tacking", "navigation.path", "navigation.prune", "content.tooltips", "content.footnote.tooltips", "header.autohide", "announce.dismiss", "toc.follow", "search.suggest", "search.highlight"], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../../assets/javascripts/bundle.13a4f30d.min.js></script> <script src=../../../overrides/js/mathjax.js></script> <script src=../../../overrides/js/tippy.js></script> <script src=../../../overrides/js/navigation.js></script> <script src=../../../overrides/js/scroll-buttons.js></script> <script src=../../../overrides/js/home/base.js></script> <script src=../../../overrides/js/home/hero.js></script> <script src=../../../overrides/js/home/why.js></script> <script src=../../../overrides/js/home/header.js></script> <script src=../../../overrides/js/home/scroll-animations.js></script> <script src=../../../overrides/js/audio-player.js></script> <script src=https://unpkg.com/@popperjs/core@2></script> <script src=https://unpkg.com/tippy.js@6></script> <script src=https://unpkg.com/tippy.js@6/dist/animations/perspective-extreme.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=../../../docs/assets/js/custom.js></script> <script type=application/ld+json>
  {
    "@context": "https://schema.org",
    "@type": "WebSite",
    "url": "https://ai-safety-atlas.com/",
    "potentialAction": {
      "@type": "SearchAction",
      "target": {
        "@type": "EntryPoint",
        "urlTemplate": "https://ai-safety-atlas.com/?q={search_term_string}"
      },
      "query-input": "required name=search_term_string"
    }
  }
</script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>