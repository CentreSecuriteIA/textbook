<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="What is AI governance? AI governance refers to the development of rules, policies, and institutions that shape how AI systems are researched, developed, and deployed. While technical AI safety work focuses on building reliable and aligned systems, governance addresses the broader challenge of managing AI's impact on society. This includes corporate practices, government regulations, standards development, and international coordination mechanisms. The goal is to ensure AI development benefits humanity while managing potential risks."><link href=https://ai-safety-atlas.com/chapters/04/01/ rel=canonical><link href=../ rel=prev><link href=../02/ rel=next><link rel=icon href=../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.14"><title>4.1 - Governance Foundations - AI Safety Atlas</title><link rel=stylesheet href=../../../assets/stylesheets/main.342714a4.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../overrides/css/base.css><link rel=stylesheet href=../../../overrides/css/buttons.css><link rel=stylesheet href=../../../overrides/css/tippy.css><link rel=stylesheet href=../../../overrides/css/tabs.css><link rel=stylesheet href=../../../overrides/css/typography.css><link rel=stylesheet href=../../../overrides/css/admonitions.css><link rel=stylesheet href=../../../overrides/css/navigation.css><link rel=stylesheet href=../../../overrides/css/metadata.css><link rel=stylesheet href=../../../overrides/css/figures.css><link rel=stylesheet href=../../../overrides/css/footer.css><link rel=stylesheet href=../../../overrides/css/section-end.css><link rel=stylesheet href=../../../overrides/css/scroll-buttons.css><link rel=stylesheet href=../../../overrides/css/home/base.css><link rel=stylesheet href=../../../overrides/css/home/hero.css><link rel=stylesheet href=../../../overrides/css/home/hero-animation.css><link rel=stylesheet href=../../../overrides/css/home/header.css><link rel=stylesheet href=../../../overrides/css/home/why.css><link rel=stylesheet href=../../../overrides/css/header.css><link rel=stylesheet href=../../../overrides/css/audio-player.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&display=swap"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Crimson+Pro:wght@700;800;900&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Cinzel:wght@600;700;800;900&display=swap"><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><link href=../../../assets/stylesheets/glightbox.min.css rel=stylesheet><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style><script src=../../../assets/javascripts/glightbox.min.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#41-governance-foundations class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="AI Safety Atlas" class="md-header__button md-logo" aria-label="AI Safety Atlas" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> AI Safety Atlas </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 4.1 - Governance Foundations </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Home </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> Book </a> </li> <li class=md-tabs__item> <a href=../../../feedback/ class=md-tabs__link> Feedback </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="AI Safety Atlas" class="md-nav__button md-logo" aria-label="AI Safety Atlas" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> AI Safety Atlas </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex> <span class=md-ellipsis> Book </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Book </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1 checked> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <span class=md-ellipsis> Chapters </span> </a> <label class="md-nav__link " for=__nav_2_1 id=__nav_2_1_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_1_label aria-expanded=true> <label class=md-nav__title for=__nav_2_1> <span class="md-nav__icon md-icon"></span> Chapters </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../01/ class=md-nav__link> <span class=md-ellipsis> 01 - Capabilities </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../02/ class=md-nav__link> <span class=md-ellipsis> 02 - Risks </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../03/ class=md-nav__link> <span class=md-ellipsis> 03 - Strategies </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1_5 checked> <div class="md-nav__link md-nav__container"> <a href=../ class="md-nav__link "> <span class=md-ellipsis> 04 - Governance </span> </a> <label class="md-nav__link " for=__nav_2_1_5 id=__nav_2_1_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_1_5_label aria-expanded=true> <label class=md-nav__title for=__nav_2_1_5> <span class="md-nav__icon md-icon"></span> 04 - Governance </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 4.1 - Governance Foundations </span> </a> </li> <li class=md-nav__item> <a href=../02/ class=md-nav__link> <span class=md-ellipsis> 4.2 - Governance Targets </span> </a> </li> <li class=md-nav__item> <a href=../03/ class=md-nav__link> <span class=md-ellipsis> 4.3 - Key issues </span> </a> </li> <li class=md-nav__item> <a href=../04/ class=md-nav__link> <span class=md-ellipsis> 4.4 - Corporate Governance </span> </a> </li> <li class=md-nav__item> <a href=../05/ class=md-nav__link> <span class=md-ellipsis> 4.5 - National Governance </span> </a> </li> <li class=md-nav__item> <a href=../06/ class=md-nav__link> <span class=md-ellipsis> 4.6 - International Governance </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../05/ class=md-nav__link> <span class=md-ellipsis> 05 - Evaluations </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../06/ class=md-nav__link> <span class=md-ellipsis> 06 - Specification </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../07/ class=md-nav__link> <span class=md-ellipsis> 07 - Generalization </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../08/ class=md-nav__link> <span class=md-ellipsis> 08 - Scalable Oversight </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../09/ class=md-nav__link> <span class=md-ellipsis> 09 - Interpretability </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../feedback/ class=md-nav__link> <span class=md-ellipsis> Feedback </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=41-governance-foundations>4.1 Governance Foundations<a class=headerlink href=#41-governance-foundations title="Permanent link">&para;</a></h1> <div class=section-meta> <div class=meta-item> <span class=meta-icon> <i class="fas fa-clock"></i> </span> <div class=meta-content> <div class=meta-label>Reading Time</div> <div class=meta-value>8 min</div> </div> </div> </div> <p><strong>What is AI governance?</strong> AI governance refers to the development of rules, policies, and institutions that shape how AI systems are researched, developed, and deployed. While technical AI safety work focuses on building reliable and aligned systems, governance addresses the broader challenge of managing AI's impact on society. This includes corporate practices, government regulations, standards development, and international coordination mechanisms. The goal is to ensure AI development benefits humanity while managing potential risks.</p> <p><strong>How do we usually govern technologies?</strong> Traditional technology governance relies on several key assumptions. First, it is usually assumed that we can predict how a technology will be used and its likely impacts. Second, that we can effectively control its development pathway. And third, that we can regulate specific applications or end-uses. For example, pharmaceutical governance uses clinical trials and approval processes based on intended medical applications. Nuclear technology is controlled through international treaties, safeguards, and monitoring of specific facilities and materials. These approaches work when technologies follow relatively predictable development paths and have clear applications.</p> <p><strong>What makes AI governance uniquely challenging?</strong> Even though we have been regulating technological advancements for decades, existing solutions to regulate “tech” might not be sufficient for AI. To better understand why AI governance resists traditional solutions, we can examine AI through three different lenses all of which might require different governance approaches (<a href=https://academic.oup.com/edited-volume/41989/chapter-abstract/408516484>Dafoe, 2022</a>):</p> <ul> <li> <p><strong>AI as general-purpose technology</strong> : AI can transform many sectors simultaneously, like electricity or computers before it. This means sector-specific regulations - the backbone of traditional technology governance - cannot adequately address AI's broad systemic effects. The impacts span across society in ways that make targeted regulation insufficient.</p> </li> <li> <p><strong>AI as an information technology</strong> : AI processes and generates information in novel ways. This creates unprecedented challenges around security, privacy, and information integrity. Traditional governance frameworks weren't designed to handle technologies that can rapidly generate and manipulate information at massive scale. The speed and scope of potential information impacts outstrip traditional control mechanisms.</p> </li> <li> <p><strong>AI as an intelligence technology</strong> : AI raises unique control challenges. As systems become more capable, they may develop sophisticated ways to evade controls or pursue unintended objectives like we highlighted in the risks chapter. There are several dangerous capabilities (e.g. autonomous replication, scheming, deception, etc.) that create fundamental challenges that we have rarely (if ever) seen in governance - how do you reliably control a system that could potentially out-think its control mechanisms?</p> </li> </ul> <p>As we saw in the capabilities chapter, we have already seen power narrow AI (ANI) but now we are continuously making systems that are both capable and increasingly general purpose.This means they become dual purpose tools that can be used for various different tasks.</p> <figure> <a class=glightbox href=../Images/x4M_Image_2.png data-type=image data-width=100% data-height=auto data-desc-position=bottom><img alt="Enter image alt description" loading=lazy src=../Images/x4M_Image_2.png></a> <br> <figcaption><b>Figure 4.2:</b> The two-dimensional outlook of capabilities and generality. The different curves are meant to represent the different paths we can take to <abbr title="Artificial Superintelligence. An AI with cognitive abilities far greater than those of humans in a wide range of important domains.">ASI</abbr>. Every single point on the path corresponds to a different level of AGI. The specific development trajectory is hard to forecast but progress is continuous.</figcaption> </figure> <p>These three lenses - general-purpose, information, and intelligence technology - help us analyze why AI development follows such different patterns than other technologies. Traditional governance assumes we can contain a technology's impact to specific sectors, control how information flows, and reliably predict and constrain system behaviors. But AI's mixed nature as a general-purpose, information processing, and potentially intelligent technology challenges all of these assumptions.</p> <p><strong>How do these three lenses create challenges for governance?</strong> Even though we have been regulating technological advancements for decades, this AI development process makes AI governance unique. Three fundamental problems emerge from these development characteristics.</p> <p><strong>The unexpected capabilities problem.</strong> AI systems can develop surprising abilities that weren't part of their intended design. (<a href=https://arxiv.org/abs/2202.07785>Ganguli et al., 2022</a>; <a href=https://arxiv.org/abs/2108.07258>Bommasani et al., 2022</a>; <a href=https://arxiv.org/abs/2401.02843>Grace et al., 2024</a>) As we saw multiple times in the capabilities chapter, foundation models have shown "emergent" capabilities that appear suddenly as models scale up with more data, parameters and compute, from becoming unexpectedly capable at basic arithmetic to complex reasoning. This makes it difficult to evaluate risks before deployment since we can't reliably predict what systems might be capable of.</p> <figure> <a class=glightbox href=../Images/unF_Image_3.png data-type=image data-width=100% data-height=auto data-desc-position=bottom><img alt="Enter image alt description" loading=lazy src=../Images/unF_Image_3.png></a> <br> <figcaption><b>Figure 4.3:</b> Example of unexpected capabilities problem. Graphs of several metrics that improve suddenly and unpredictably as models increase in size (<a href=https://arxiv.org/abs/2202.07785>Ganguli et al., 2022</a>)</figcaption> </figure> <p><strong>The deployment safety problem.</strong> Once deployed, AI systems can be repurposed for many different applications - both beneficial and harmful. These systems are inherently dual-use - their capabilities can be redirected toward unintended purposes after deployment. Users regularly discover new capabilities that weren't anticipated by the original developers (<a href=https://www.gov.uk/government/publications/frontier-ai-capabilities-and-risks-discussion-paper/frontier-ai-capabilities-and-risks-discussion-paper>U.K. government, 2023</a>). We dedicated several sections in the risks chapter to this and saw many different ways that problems can arise. The problem begins with simple circumvention of safety measures - users have found numerous "jailbreaks" to bypass content restrictions in language models (Anderljung et al., 2023). But the challenges escalate quickly. Language models trained for helpful dialogue have been repurposed to generate misinformation (<a href=https://arxiv.org/abs/2408.12622>Slattery et al., 2024</a>) and assist with cyberattacks (<a href=https://www.safe.ai/blog/cybersecurity-and-ai-the-evolving-security-landscape>CAIS, 2024</a>; <a href=https://axrp.net/episode/2024/04/30/episode-30-ai-security-jeffrey-ladish.html>Ladish, 2024</a>), potentially even designing novel bio weapons (<a href=https://arxiv.org/abs/2306.12001>Hendrycks 2023</a>; <a href=https://arxiv.org/abs/2406.13843>Marchal et al., 2024</a>; <a href=https://arxiv.org/abs/2402.06664>Fang et al., 2024</a>). We are now also seeing the emergence of autonomous AI agents that can chain together model capabilities in novel and unpredictable ways using new tools post deployment.</p> <figure> <a class=glightbox href=../Images/2JM_Image_4.png data-type=image data-width=100% data-height=auto data-desc-position=bottom><img alt="Enter image alt description" loading=lazy src=../Images/2JM_Image_4.png></a> <br> <figcaption><b>Figure 4.4:</b> Example of deployment safety problem. A schematic of using autonomous LLM agents to hack websites. (<a href=https://arxiv.org/abs/2402.06664>Fang et al., 2024</a>) Once a dual purpose technology is public, it can be used for a variety of things both beneficial and harmful.</figcaption> </figure> <p><strong>The proliferation problem.</strong> AI capabilities can spread rapidly through multiple channels - open-source releases, model theft, or reproduction by other actors. As we saw in the strategies chapter, once capabilities exist, they become very difficult to contain. Models can be stolen, leaked, or reproduced by other groups within months. One example is the rapid open-source replication of ChatGPT-like capabilities, leading to discovery of new capabilities and removal of safety features (<a href=https://arxiv.org/abs/2406.13843>Solaiman et al., 2024</a>) Even API-based models can have their capabilities extracted through techniques like model distillation. (<a href=https://www.gov.uk/government/publications/frontier-ai-capabilities-and-risks-discussion-paper/frontier-ai-capabilities-and-risks-discussion-paper>U.K. government, 2023</a>)</p> <p><strong>How do these problems interact and compound?</strong> These challenges don't exist in isolation - they interact and amplify each other in ways that make AI governance even harder. The unexpected capabilities problem makes deployment safety more difficult to ensure, since we can't reliably predict what abilities might emerge that could be misused. The deployment flexibility of AI systems makes proliferation more concerning, since capabilities can be repurposed for harmful uses after they spread. And proliferation increases the chances of discovering unexpected capabilities through experimentation by many actors (<a href=https://arxiv.org/abs/2307.03718>Anderljung et al., 2023</a>).</p> <p><strong>What is the function of governance?</strong> Governance is not solely about restrictions; it also encompasses functions that facilitate responsible innovation, such as providing guidance, fostering collaboration, and creating safe spaces for experimentation. Although we’re concerned with challenges whose answers mostly rely on setting guardrails, these enabling functions are equally important. Governance fulfills several key functions. A couple of examples include:</p> <ul> <li> <p><strong>Visibility</strong> : Enhanced visibility is fundamental to effective oversight. It involves creating mechanisms that bring transparency to AI development processes, allowing stakeholders to understand and monitor the progress and potential impacts of AI. Visibility enables verification - the confirmation of claims made by AI developers or other actors and the assessment of AI systems against established standards or benchmarks.</p> </li> <li> <p><strong>Enforcement</strong> : Governance needs to provide the means to ensure compliance with regulations and ethical guidelines. This can range from legal sanctions to market exclusions for non-compliant actors.</p> </li> </ul> <p><strong>What levers can governance use to affect these targets?</strong> To execute these functions, governance systems employ a variety of mechanisms (<a href=https://www.taylorfrancis.com/books/mono/10.4324/9781315232003/designing-public-policies-michael-howlett-michael-howlett>Howlett, 2019</a>). Here are examples of just a few of the mechanisms that governance has on hand to affect the chosen governance target:</p> <ul> <li> <p><strong>Information-based tools</strong> : We can leverage the power of knowledge dissemination. These might include mandatory disclosure requirements for AI companies or public education initiatives to increase AI literacy.</p> </li> <li> <p><strong>Authoritative tools</strong> : We can draw upon the power of institutions to set and enforce rules. This could involve legislation, executive orders, or judicial decisions that directly regulate AI development and use.</p> </li> <li> <p><strong>Standards</strong> : These play a core role in AI governance, serving as a bridge between broad principles and specific practices (<a href=https://www.governance.ai/research-paper/standards-for-ai-governance-international-standards-to-enable-global-coordination-in-ai-research-development>Cihon, 2019</a>). They can be technical, like those defining AI performance metrics, or ethical, outlining acceptable practices in AI development.</p> </li> <li> <p><strong>Incentives</strong> : This mechanism helps shape behavior through rewards and penalties. These can be financial, such as tax breaks for companies investing in AI safety research, or reputational, like certification schemes that recognize responsible AI practices. By aligning economic and social motivations with governance objectives, incentives can drive voluntary compliance and innovation in governance approaches.</p> </li> </ul> <p><strong>What does this mean for governance approaches?</strong> These fundamental challenges - unexpected capabilities, deployment safety risks, and rapid proliferation - mean we need new approaches to governing AI development. Traditional regulatory tools like application-specific permits or post-deployment monitoring won't be sufficient given AI's unique characteristics. To build effective governance, we need to identify what aspects of the AI development pipeline we can meaningfully influence before capabilities emerge or proliferate. We need to understand which intervention points give us the most leverage while allowing beneficial innovation to continue. In the next section, we'll examine specific targets along the AI development and deployment pipeline - from key inputs like compute and data to deployment controls and monitoring systems - evaluating each through the lens of these core challenges.</p> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=footer.title> <a href=../ class="md-footer__link md-footer__link--prev" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction>Previous</span> Chapter 04 </div> </div> </a> <a href=../02/ class="md-footer__link md-footer__link--next" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction>Next</span> 4.2 - Governance Targets </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=footer-social-container> <hr class=footer-line> <div class=footer-social> <a href=https://github.com/CentreSecuriteIA class="footer-social__link github" title=GitHub> <i class="fab fa-github"></i> </a> <a href=https://youtube.com/@securite-ia class="footer-social__link youtube" title=YouTube> <i class="fab fa-youtube"></i> </a> <a href=https://discord.gg/YtatCZ3SQ8 class="footer-social__link discord" title=Discord> <i class="fab fa-discord"></i> </a> </div> <hr class=footer-line> </div> <div class=footer-identity> <a href=https://www.securite-ia.fr/ class=footer-logo target=_blank rel=noopener> <img src=https://ai-safety-atlas.com/assets/CeSIA_transparent_white_pure.png alt="CeSIA - French Center for AI Safety"> </a> </div> <div class=footer-info> <div class=footer-links> <a href=mailto:contact@securite-ia.fr>Contact</a> <span class=separator>•</span> <a href=https://forms.gle/Z3rzFfCrLJdDv8HDA>Feedback</a> </div> <div class=footer-legal> <span>© Copyright 2025 </span> <span class=separator>•</span> <span>Text Content: <a href=https://creativecommons.org/licenses/by-sa/4.0/ >CC BY-SA 4.0</a></span> <span class=separator>•</span> <span>Code: <a href=https://opensource.org/licenses/MIT>MIT</a></span> </div> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["navigation.tabs", "navigation.indexes", "navigation.footer", "navigation.sections", "navigation.tacking", "navigation.path", "navigation.prune", "content.tooltips", "content.footnote.tooltips", "header.autohide", "announce.dismiss", "toc.follow", "search.suggest", "search.highlight"], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../../assets/javascripts/bundle.13a4f30d.min.js></script> <script src=../../../overrides/js/mathjax.js></script> <script src=../../../overrides/js/tippy.js></script> <script src=../../../overrides/js/navigation.js></script> <script src=../../../overrides/js/scroll-buttons.js></script> <script src=../../../overrides/js/home/base.js></script> <script src=../../../overrides/js/home/hero.js></script> <script src=../../../overrides/js/home/why.js></script> <script src=../../../overrides/js/home/header.js></script> <script src=../../../overrides/js/home/scroll-animations.js></script> <script src=../../../overrides/js/audio-player.js></script> <script src=https://unpkg.com/@popperjs/core@2></script> <script src=https://unpkg.com/tippy.js@6></script> <script src=https://unpkg.com/tippy.js@6/dist/animations/perspective-extreme.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=../../../docs/assets/js/custom.js></script> <script type=application/ld+json>
  {
    "@context": "https://schema.org",
    "@type": "WebSite",
    "url": "https://ai-safety-atlas.com/",
    "potentialAction": {
      "@type": "SearchAction",
      "target": {
        "@type": "EntryPoint",
        "urlTemplate": "https://ai-safety-atlas.com/?q={search_term_string}"
      },
      "query-input": "required name=search_term_string"
    }
  }
</script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>